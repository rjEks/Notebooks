{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-0ac448759ac3>, line 43)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-0ac448759ac3>\"\u001b[1;36m, line \u001b[1;32m43\u001b[0m\n\u001b[1;33m    print(total_de_acertos)este)\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "######################CAPITULO 1 ########################################################################\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Atribuido condições para os animais\n",
    "\n",
    "porco1 = [1,1,0]\n",
    "porco2 = [1,1,0]\n",
    "porco3 = [1,1,0]\n",
    "cachorro4 = [1,1,1]\n",
    "cachorro5 = [0,1,1]\n",
    "cachorro6 = [0,1,1]\n",
    "\n",
    "dados = [porco1,porco2,porco3,cachorro4,cachorro5,cachorro6]\n",
    "\n",
    "# 1 porco, -1 cachorro\n",
    "\n",
    "marcacoes  = [1,1,1,-1,-1,-1]\n",
    "\n",
    "misterioso1  = [1, 1, 1]\n",
    "misterioso2 = [1, 0, 0]\n",
    "misterioso3 = [0,0,1]\n",
    "\n",
    "teste = [misterioso1,misterioso2,misterioso3]\n",
    "\n",
    "marcacoes_teste = [-1,1,-1]\n",
    "\n",
    "modelo = MultinomialNB()\n",
    "\n",
    "modelo.fit(dados,marcacoes)\n",
    "\n",
    "resultado = modelo.predict(teste)\n",
    "\n",
    "diferencas = resultado - marcacoes_teste\n",
    "\n",
    "acertos = [d for d in diferencas if d == 0]\n",
    "\n",
    "total_de_acertos = len(acertos)\n",
    "\n",
    "total_de_elementos = len(t\n",
    "print(total_de_acertos)este)\n",
    "\n",
    "print(total_de_elementos)\n",
    "\n",
    "taxa_de_acerto =  100.0 * total_de_acertos / total_de_elementos\n",
    "\n",
    "print(taxa_de_acerto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.88888888888889\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "######################CAPITULO 2 ########################################################################\n",
    "\n",
    "import csv\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def carrega_acessos():\n",
    "    X =[]\n",
    "    Y =[]\n",
    "    \n",
    "    arquivo = open('D:\\\\Users\\\\313432\\\\Desktop\\\\Police Deaths\\\\machine-learning-master\\\\capitulo2\\\\acesso.csv', 'r')\n",
    "    leitor = csv.reader(arquivo)\n",
    "    \n",
    "    next(leitor)\n",
    "    \n",
    "    for home, como_funciona, contato, comprou in leitor:\n",
    "        \n",
    "        dado = [int(home),int(como_funciona),int(contato)]\n",
    "        X.append(dado)\n",
    "        Y.append(int(comprou))\n",
    "        \n",
    "\n",
    "    return X, Y\n",
    "\n",
    "# CARREGANDO DADOS\n",
    "X, Y = carrega_acessos()\n",
    "\n",
    "#DIVIDINDO ENTRE TREINO E TESTE - 1. separar 90% para treino e 10% para teste: 88.89%\n",
    "treino_dados = X[:90]\n",
    "treino_marcacoes=Y[:90]\n",
    "\n",
    "teste_dados = X[-9:]\n",
    "teste_marcacoes = Y[-9:]\n",
    "\n",
    "# CRIANDO MODELO\n",
    "modelo = MultinomialNB()\n",
    "\n",
    "#TREINANDO NOSSO MODELO\n",
    "modelo.fit(treino_dados, treino_marcacoes)\n",
    "\n",
    "#TESTANDO PREDIÇÃO\n",
    "#print(modelo.predict([[1,0,1],[0,1,0],[1,0,0],[1,1,0],[1,1,1]]))\n",
    "\n",
    "resultado = modelo.predict(teste_dados)\n",
    "\n",
    "#CALCULANDO NOSSA TAXA DE ACERTO\n",
    "diferencas = resultado - teste_marcacoes\n",
    "\n",
    "acertos = [d for d in diferencas if d == 0]\n",
    "total_de_acertos = len(acertos)\n",
    "total_de_elementos = len(teste_dados)\n",
    "\n",
    "taxa_de_acerto = 100.0 * total_de_acertos / total_de_elementos\n",
    "\n",
    "print(taxa_de_acerto)\n",
    "print(total_de_elementos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.0\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "######################CAPITULO 3 ########################################################################\n",
    "import csv\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def carregar_acessos():\n",
    "    X = []\n",
    "    Y = []\n",
    "    arquivo = open('D:\\\\Users\\\\313432\\\\Desktop\\\\Police Deaths\\\\machine-learning-master\\\\capitulo3\\\\acesso.csv', 'r')\n",
    "    \n",
    "    leitor = csv.reader(arquivo)\n",
    "    next(leitor)\n",
    "    \n",
    "    for home,planos_de_cursos,contato,comprou in leitor:\n",
    "        \n",
    "        dado = ([int(home),int(planos_de_cursos),int(contato)])\n",
    "        \n",
    "        X.append(dado)\n",
    "        Y.append(int(comprou))\n",
    "        \n",
    "    return X, Y\n",
    "\n",
    "def carregar_buscas():\n",
    "    X = []\n",
    "    Y = []\n",
    "    arquivo = open('D:\\\\Users\\\\313432\\\\Desktop\\\\Police Deaths\\\\machine-learning-master\\\\capitulo3\\\\buscas.csv', 'r')\n",
    "    leitor = csv.reader(arquivo)\n",
    "    \n",
    "    next(leitor)\n",
    "    \n",
    "    for home,busca,logado,comprou in leitor:\n",
    "        \n",
    "        dado = ([int(home),busca,int(logado)])\n",
    "        \n",
    "        X.append(dado)\n",
    "        Y.append(int(comprou))\n",
    "        \n",
    "    return X, Y\n",
    "#####################################################################PANDAS###########################################\n",
    "X,Y = carregar_buscas()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('D:\\\\Users\\\\313432\\\\Desktop\\\\Police Deaths\\\\machine-learning-master\\\\capitulo3\\\\buscas.csv')\n",
    "X_df = df[['home', 'busca', 'logado']]\n",
    "Y_df = df['comprou']\n",
    "\n",
    "Xdummies_df = pd.get_dummies(X_df)\n",
    "Ydummies_df = Y_df\n",
    "\n",
    "X = Xdummies_df.values\n",
    "Y = Ydummies_df.values\n",
    "\n",
    "#obtendo 90% dos dados para treino \n",
    "porcentagem_treino = 0.9\n",
    "\n",
    "tamanho_de_treino = int(porcentagem_treino * len(Y))\n",
    "tamanho_de_teste = len(Y) - tamanho_de_treino\n",
    "\n",
    "treino_dados = X[:tamanho_de_treino]\n",
    "teste_dados = X[-tamanho_de_teste:]\n",
    "\n",
    "#obtendo 90% dos dados de marcação\n",
    "treino_marcacoes = Y[:tamanho_de_treino]\n",
    "teste_marcacoes = Y[-tamanho_de_teste:]\n",
    "\n",
    "#criando modelo e treinando\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(treino_dados, treino_marcacoes)\n",
    "\n",
    "#Realizando predict e analisando saida\n",
    "resultado = modelo.predict(teste_dados)\n",
    "\n",
    "diferencas = resultado - teste_marcacoes\n",
    "\n",
    "acertos = [d for d in diferencas if d == 0]\n",
    "\n",
    "total_de_acertos = len(acertos)\n",
    "total_de_elementos = len(teste_dados)\n",
    "\n",
    "taxa_de_acerto = 100.0 * total_de_acertos / total_de_elementos\n",
    "\n",
    "print(taxa_de_acerto)\n",
    "print(total_de_elementos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.0\n",
      "100\n",
      "Taxa de acerto base: 82.000000\n"
     ]
    }
   ],
   "source": [
    "############################################CAPITULO 4 #############################################################\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "df = pd.read_csv('D:\\\\Users\\\\313432\\\\Desktop\\\\Police Deaths\\\\machine-learning-master\\\\capitulo4\\\\buscas.csv')\n",
    "X_df = df[['home', 'busca', 'logado']]\n",
    "Y_df = df['comprou']\n",
    "\n",
    "Xdummies_df = pd.get_dummies(X_df)\n",
    "Ydummies_df = Y_df\n",
    "\n",
    "X = Xdummies_df.values\n",
    "Y = Ydummies_df.values\n",
    "\n",
    "#Convertendo os dados SIM e NAO para true e false, facilitando a analise.\n",
    "#PORCENTAGEM DE DADOS PARA TREINO\n",
    "porcentagem_treino = 0.9\n",
    "\n",
    "#TAMANHO DO TREINO - 900\n",
    "tamanho_de_treino = int(porcentagem_treino * len(Y))\n",
    "\n",
    "#TAMANHO DO TESTE - 100\n",
    "tamanho_de_teste = len(Y) - tamanho_de_treino\n",
    "\n",
    "#OBTENDO ARRAY DE TREINO\n",
    "treino_dados = X[:tamanho_de_treino]\n",
    "treino_marcacoes = Y[:tamanho_de_treino]\n",
    "\n",
    "#OBTENDO ARRAY DE TESTE\n",
    "teste_dados = X[-tamanho_de_teste:]\n",
    "teste_marcacoes = Y[-tamanho_de_teste:]\n",
    "\n",
    "#CRIANDO MODELO E AJUSTANDO - O\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(treino_dados, treino_marcacoes)\n",
    "\n",
    "#RESULTADO DA PREDIÇAO\n",
    "resultado = modelo.predict(teste_dados)\n",
    "\n",
    "#CONTABILIZANDO ACERTOS\n",
    "acertos = resultado == teste_marcacoes\n",
    "\n",
    "#OBTENDO TAXAS DE ASSERITIVIDADE\n",
    "total_de_acertos = sum(acertos)\n",
    "total_de_elementos = len(teste_dados)\n",
    "\n",
    "#CALCULO DE TAXAS\n",
    "taxa_de_acerto = 100.0 * total_de_acertos / total_de_elementos\n",
    "\n",
    "#APRESENTANDO OS DADOS\n",
    "print(taxa_de_acerto)\n",
    "print(total_de_elementos)\n",
    "\n",
    "#Criando acerto_base com Counter\n",
    "acerto_base = max(Counter(teste_marcacoes).values())\n",
    "\n",
    "# a eficácia do algoritmo que chuta tudo 0 ou 1\n",
    "taxa_de_acerto_base = 1000 * acerto_base  / len(Y)\n",
    "\n",
    "#imprimindo taxas de acerto do algoritmo base e Navie Bayes\n",
    "print(\"Taxa de acerto base: %f\" % taxa_de_acerto_base) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto do algoritmo MultinomialNB: 85.71428571428571\n",
      "Taxa de acerto do algoritmo AdaBoostClassifier: 85.71428571428571\n",
      "Taxa de acerto do vencedor entre os dois algoritmos no mundo real: 62.5\n",
      "Taxa de acerto base: 62.500000\n",
      "Total de teste: 8\n"
     ]
    }
   ],
   "source": [
    "######################################## CAPITULO 6 ##########################\n",
    "\n",
    "# VERIFICANDO A TAXA DE ACERTO DO MODELO COM NOVOS DADOS\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "df = pd.read_csv('D:\\\\Users\\\\313432\\\\Desktop\\\\Police Deaths\\\\machine-learning-master\\\\capitulo6\\\\buscas2.csv')\n",
    "\n",
    "X_df = df[['home','busca','logado']]\n",
    "Y_df = df['comprou']\n",
    "\n",
    "Xdummies_df = pd.get_dummies(X_df)\n",
    "Ydummies_df = Y_df\n",
    "\n",
    "X = Xdummies_df.values\n",
    "Y = Ydummies_df.values\n",
    "\n",
    "#Convertendo os dados SIM e NAO para true e false, facilitando a analise.\n",
    "#PORCENTAGEM DE DADOS PARA TREINO\n",
    "porcentagem_de_treino = 0.8\n",
    "porcentagem_de_teste = 0.1\n",
    "\n",
    "#TAMANHO DO TREINO - 900\n",
    "tamanho_de_treino = int(porcentagem_de_treino * len(Y))\n",
    "\n",
    "#TAMANHO DO TESTE - 100\n",
    "tamanho_de_teste =int(porcentagem_de_teste * len(Y))\n",
    "\n",
    "#Validação mundo real\n",
    "tamanho_de_validacao = len(Y) - tamanho_de_treino - tamanho_de_teste\n",
    "\n",
    "#OBTENDO ARRAY DE TREINO\n",
    "treino_dados = X[:tamanho_de_treino]\n",
    "treino_marcacoes = Y[:tamanho_de_treino]\n",
    "\n",
    "fim_de_treino = tamanho_de_treino + tamanho_de_teste\n",
    "\n",
    "#OBTENDO ARRAY DE TESTE - modificado\n",
    "teste_dados = X[tamanho_de_treino:fim_de_treino]\n",
    "teste_marcacoes = Y[tamanho_de_treino:fim_de_treino]\n",
    "\n",
    "#DADOS VALIDAÇÃO MUNDO REAL\n",
    "validacao_dados = X[fim_de_treino:]\n",
    "validacao_marcacoes = Y[fim_de_treino:]\n",
    "\n",
    "#CRIANDO MODELO E AJUSTANDO - O\n",
    "modelo = AdaBoostClassifier()\n",
    "\n",
    "def fit_and_predict(nome,modelo, treino_dados, treino_marcacoes, teste_dados, teste_marcacoes):\n",
    "        \n",
    "    modelo.fit(treino_dados, treino_marcacoes)\n",
    "\n",
    "    #RESULTADO DA PREDIÇAO\n",
    "    resultado = modelo.predict(teste_dados)\n",
    "\n",
    "    #CONTABILIZANDO ACERTOS\n",
    "    acertos = resultado == teste_marcacoes\n",
    "\n",
    "    #OBTENDO TAXAS DE ASSERITIVIDADE\n",
    "    total_de_acertos = sum(acertos)\n",
    "    total_de_elementos = len(teste_dados)\n",
    "\n",
    "    #CALCULO DE TAXAS\n",
    "    taxa_de_acerto = 100.0 * total_de_acertos / total_de_elementos\n",
    "    msg = \"Taxa de acerto do algoritmo {0}: {1}\".format(nome, taxa_de_acerto)\n",
    "    print(msg)\n",
    "    \n",
    "    return taxa_de_acerto\n",
    "\n",
    "#Criando função de teste real\n",
    "def teste_real(modelo, validacao_dados, validacao_marcacoes):\n",
    "    \n",
    "    resultado = modelo.predict(validacao_dados)\n",
    "    acertos = resultado == validacao_marcacoes\n",
    "    \n",
    "    total_de_acertos = sum(acertos)\n",
    "    total_de_elementos = len(validacao_marcacoes)\n",
    "    taxa_de_acerto = 100.0 * total_de_acertos / total_de_elementos\n",
    "\n",
    "    msg = \"Taxa de acerto do vencedor entre os dois algoritmos no mundo real: {0}\".format(taxa_de_acerto)\n",
    "    print(msg)\n",
    "\n",
    "#Validando e obtendo resultados - modelo multibinomial\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "modeloMultinomial = MultinomialNB()\n",
    "resultadoMultinomial = fit_and_predict(\"MultinomialNB\", modeloMultinomial, treino_dados, treino_marcacoes, teste_dados, teste_marcacoes)\n",
    "\n",
    "#Validando e obtendo resultados - modelo AdaboostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "modeloAdaBoost = AdaBoostClassifier()\n",
    "resultadoAdaBoost = fit_and_predict(\"AdaBoostClassifier\", modeloAdaBoost, treino_dados, treino_marcacoes, teste_dados, teste_marcacoes)\n",
    "\n",
    "#Verificando melhor algoritmo\n",
    "if resultadoMultinomial > resultadoAdaBoost:\n",
    "    vencedor = modeloMultinomial\n",
    "else:\n",
    "    vencedor = modeloAdaBoost\n",
    "\n",
    "#Testando com dados reais\n",
    "teste_real(vencedor, validacao_dados, validacao_marcacoes)\n",
    "\n",
    "#Acerto Base\n",
    "acerto_base = max(Counter(validacao_marcacoes).values())\n",
    "\n",
    "#Taxa Acerto base\n",
    "taxa_de_acerto_base = 100.0 * acerto_base / len(validacao_marcacoes)\n",
    "\n",
    "#Imprimindo x2\n",
    "print(\"Taxa de acerto base: %f\" % taxa_de_acerto_base)\n",
    "total_de_elementos = len(validacao_dados)\n",
    "\n",
    "print(\"Total de teste: %d\" % total_de_elementos)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto do algoritmo OneVsRest: 90.9090909090909\n",
      "Taxa de acerto do algoritmo OneVsOne: 100.0\n",
      "Taxa de acerto do algoritmo MultinomialNB: 72.72727272727273\n",
      "Taxa de acerto do algoritmo AdaBoostClassifier: 68.18181818181819\n",
      "Vencedor: \n",
      "OneVsOneClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "     verbose=0),\n",
      "          n_jobs=1)\n",
      "Taxa de acerto do vencedor entre os dois algoritmos no mundo real: 100.0\n",
      "Counter({1: 19, 0: 3, 2: 1})\n",
      "Taxa de acerto base: 82.608696\n",
      "Total de teste: 23\n"
     ]
    }
   ],
   "source": [
    "######################################## CAPITULO 7 ##########################\n",
    "\n",
    "# VERIFICANDO A TAXA DE ACERTO DO MODELO COM NOVOS DADOS\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "df = pd.read_csv('D:\\\\Users\\\\313432\\\\Desktop\\\\Police Deaths\\\\machine-learning-master\\\\capitulo7\\\\situacao_do_cliente.csv')\n",
    "\n",
    "X_df = df[['recencia','frequencia','semanas_de_inscricao']]\n",
    "Y_df = df['situacao']\n",
    "\n",
    "Xdummies_df = pd.get_dummies(X_df)\n",
    "Ydummies_df = Y_df\n",
    "\n",
    "X = Xdummies_df.values\n",
    "Y = Ydummies_df.values\n",
    "\n",
    "porcentagem_de_treino = 0.8\n",
    "porcentagem_de_teste = 0.1\n",
    "\n",
    "tamanho_de_treino = int(porcentagem_de_treino * len(Y))\n",
    "tamanho_de_teste = int(porcentagem_de_teste * len(Y))\n",
    "tamanho_de_validacao = len(Y) - tamanho_de_treino - tamanho_de_teste\n",
    "\n",
    "treino_dados = X[:tamanho_de_treino]\n",
    "treino_marcacoes = Y[:tamanho_de_treino]\n",
    "\n",
    "fim_de_treino = tamanho_de_treino + tamanho_de_teste\n",
    "\n",
    "teste_dados = X[tamanho_de_treino:fim_de_treino]\n",
    "teste_marcacoes = Y[tamanho_de_treino:fim_de_treino]\n",
    "\n",
    "validacao_dados = X[fim_de_treino:]\n",
    "validacao_marcacoes = Y[fim_de_treino:]\n",
    "\n",
    "\n",
    "def fit_and_predict(nome, modelo, treino_dados, treino_marcacoes, teste_dados, teste_marcacoes):\n",
    "        modelo.fit(treino_dados, treino_marcacoes)\n",
    "\n",
    "        resultado = modelo.predict(teste_dados)\n",
    "\n",
    "        acertos = resultado == teste_marcacoes\n",
    "\n",
    "        total_de_acertos = sum(acertos)\n",
    "        total_de_elementos = len(teste_dados)\n",
    "\n",
    "        taxa_de_acerto = 100.0 * total_de_acertos / total_de_elementos\n",
    "\n",
    "        msg = \"Taxa de acerto do algoritmo {0}: {1}\".format(nome, taxa_de_acerto)\n",
    "\n",
    "        print(msg)\n",
    "        return taxa_de_acerto\n",
    "\n",
    "def teste_real(modelo, validacao_dados, validacao_marcacoes):\n",
    "        resultado = modelo.predict(validacao_dados)\n",
    "        acertos = resultado == validacao_marcacoes\n",
    "\n",
    "        total_de_acertos = sum(acertos)\n",
    "        total_de_elementos = len(validacao_marcacoes)\n",
    "\n",
    "        taxa_de_acerto = 100.0 * total_de_acertos / total_de_elementos\n",
    "\n",
    "        msg = \"Taxa de acerto do vencedor entre os dois algoritmos no mundo real: {0}\".format(taxa_de_acerto)\n",
    "        print(msg)\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "modeloOneVsRest = OneVsRestClassifier(LinearSVC(random_state = 0))\n",
    "resultadoOneVsRest = fit_and_predict(\"OneVsRest\", modeloOneVsRest, treino_dados, treino_marcacoes, teste_dados, teste_marcacoes)\n",
    "resultados[resultadoOneVsRest] = modeloOneVsRest\n",
    "# 0=>0 1=>1,2 LinearSVC 0 ou do resto (38%, resto 62%)\n",
    "# 0=>0,2 1=>1 LinearSVC 1 ou do resto (44%, resto 56%)\n",
    "# 0=>0,1 2=>2 LinearSVC 2 ou do resto (20%, resto 80%)\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "modeloOneVsOne = OneVsOneClassifier(LinearSVC(random_state = 0))\n",
    "resultadoOneVsOne = fit_and_predict(\"OneVsOne\", modeloOneVsOne, treino_dados, treino_marcacoes, teste_dados, teste_marcacoes)\n",
    "resultados[resultadoOneVsOne] = modeloOneVsOne\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "modeloMultinomial = MultinomialNB()\n",
    "resultadoMultinomial = fit_and_predict(\"MultinomialNB\", modeloMultinomial, treino_dados, treino_marcacoes, teste_dados, teste_marcacoes)\n",
    "resultados[resultadoMultinomial] = modeloMultinomial\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "modeloAdaBoost = AdaBoostClassifier()\n",
    "resultadoAdaBoost = fit_and_predict(\"AdaBoostClassifier\", modeloAdaBoost, treino_dados, treino_marcacoes, teste_dados, teste_marcacoes)\n",
    "resultados[resultadoAdaBoost] = modeloAdaBoost\n",
    "\n",
    "maximo = max(resultados)\n",
    "vencedor = resultados[maximo]\n",
    "print(\"Vencedor: \")\n",
    "print(vencedor)\n",
    "\n",
    "teste_real(vencedor, validacao_dados, validacao_marcacoes)\n",
    "\n",
    "print(Counter(validacao_marcacoes))\n",
    "acerto_base = max(Counter(validacao_marcacoes).values())\n",
    "taxa_de_acerto_base = 100.0 * acerto_base / len(validacao_marcacoes)\n",
    "print(\"Taxa de acerto base: %f\" % taxa_de_acerto_base)\n",
    "\n",
    "total_de_elementos = len(validacao_dados)\n",
    "print(\"Total de teste: %d\" % total_de_elementos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto do OneVsRest: 0.9284012727898177\n",
      "Taxa de acerto do OneVsOne: 0.9944444444444445\n",
      "Taxa de acerto do MultinomialNB: 0.8299772101823185\n",
      "Taxa de acerto do AdaBoostClassifier: 0.7629471964224286\n",
      "{0.92840127278981766: OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "     verbose=0),\n",
      "          n_jobs=1), 0.99444444444444446: OneVsOneClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "     verbose=0),\n",
      "          n_jobs=1), 0.82997721018231851: MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 0.76294719642242859: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)}\n"
     ]
    }
   ],
   "source": [
    "######################################## CAPITULO 8 ##########################\n",
    "\n",
    "# VERIFICANDO A TAXA DE ACERTO DO MODELO COM NOVOS DADOS\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('D:\\\\Users\\\\313432\\\\Desktop\\\\Police Deaths\\\\machine-learning-master\\\\capitulo7\\\\situacao_do_cliente.csv')\n",
    "\n",
    "X_df = df[['recencia','frequencia','semanas_de_inscricao']]\n",
    "Y_df = df['situacao']\n",
    "\n",
    "Xdummies_df = pd.get_dummies(X_df)\n",
    "Ydummies_df = Y_df\n",
    "\n",
    "X = Xdummies_df.values\n",
    "Y = Ydummies_df.values\n",
    "\n",
    "\n",
    "#MODIFICAÇÃO PARA O K-FOLD\n",
    "\n",
    "porcentagem_de_treino = 0.8\n",
    "tamanho_de_treino = int(porcentagem_de_treino * len(Y))\n",
    "\n",
    "treino_dados = X[:tamanho_de_treino]\n",
    "treino_marcacoes = Y[:tamanho_de_treino]\n",
    "\n",
    "validacao_dados = X[tamanho_de_treino:]\n",
    "validacao_marcacoes = Y[tamanho_de_treino:]\n",
    "\n",
    "\n",
    "def fit_and_predict(nome, modelo, treino_dados, treino_marcacoes):\n",
    "    \n",
    "    k=10\n",
    "    \n",
    "    scores = cross_val_score(modelo, treino_dados, treino_marcacoes, cv = k)\n",
    "    \n",
    "    taxa_de_acerto = np.mean(scores)\n",
    "    \n",
    "    msg = \"Taxa de acerto do {0}: {1}\".format(nome, taxa_de_acerto)\n",
    "    print(msg)\n",
    "    return taxa_de_acerto\n",
    "\n",
    "\n",
    "def teste_real(modelo, validacao_dados, validacao_marcacoes):\n",
    "    \n",
    "    resultado = modelo.predict(validacao_dados)\n",
    "    acertos = resultado == validacao_marcacoes\n",
    "    \n",
    "    total_de_acertos = sum(acertos)\n",
    "    total_de_elementos = len(validacao_marcacoes)\n",
    "    \n",
    "    taxa_de_acerto = 100.0 * total_de_acertos / total_de_elementos\n",
    "    \n",
    "    msg = \"Taxa de acerto do vencedor entre os dois algoritmos no mundo real: {0}\".format(taxa_de_acerto)\n",
    "        \n",
    "    print(msg)\n",
    "\n",
    "resultados ={}\n",
    "\n",
    "modeloOneVsRest = OneVsRestClassifier(LinearSVC(random_state = 0))\n",
    "resultadoOneVsRest = fit_and_predict(\"OneVsRest\", modeloOneVsRest, treino_dados, treino_marcacoes)\n",
    "resultados[resultadoOneVsRest] = modeloOneVsRest\n",
    "\n",
    "modeloOneVsOne = OneVsOneClassifier(LinearSVC(random_state = 0))\n",
    "resultadoOneVsOne = fit_and_predict(\"OneVsOne\", modeloOneVsOne, treino_dados, treino_marcacoes)\n",
    "resultados[resultadoOneVsOne] = modeloOneVsOne\n",
    "\n",
    "modeloMultinomial = MultinomialNB()\n",
    "resultadoMultinomial = fit_and_predict(\"MultinomialNB\", modeloMultinomial, treino_dados, treino_marcacoes)\n",
    "resultados[resultadoMultinomial] = modeloMultinomial\n",
    "\n",
    "modeloAdaBoost = AdaBoostClassifier()\n",
    "resultadoAdaBoost = fit_and_predict(\"AdaBoostClassifier\", modeloAdaBoost, treino_dados, treino_marcacoes)\n",
    "resultados[resultadoAdaBoost] = modeloAdaBoost\n",
    "\n",
    "print(resultados)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vencedor: \n",
      "OneVsOneClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "     verbose=0),\n",
      "          n_jobs=1)\n",
      "Taxa de acerto do vencedor entre os dois algoritmos no mundo real: 100.0\n",
      "Taxa de acerto base: 75.555556\n",
      "Total de teste: 45\n"
     ]
    }
   ],
   "source": [
    "maximo = max(resultados)\n",
    "vencedor = resultados[maximo]\n",
    "\n",
    "print(\"Vencedor: \")\n",
    "print(vencedor)\n",
    "\n",
    "vencedor.fit(treino_dados, treino_marcacoes)\n",
    "\n",
    "teste_real(vencedor, validacao_dados, validacao_marcacoes)\n",
    "acerto_base = max(Counter(validacao_marcacoes).values())\n",
    "taxa_de_acerto_base = 100.0 * acerto_base / len(validacao_marcacoes)\n",
    "\n",
    "print(\"Taxa de acerto base: %f\" % taxa_de_acerto_base)\n",
    "total_de_elementos = len(validacao_dados)\n",
    "print(\"Total de teste: %d\" % total_de_elementos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto do OneVsRest: 0.7233333333333334\n",
      "Taxa de acerto do OneVsOne: 0.6566666666666666\n",
      "Taxa de acerto do MultinomialNB: 0.7150000000000001\n",
      "Taxa de acerto do AdaBoostClassifier: 0.4733333333333333\n",
      "{0.72333333333333338: OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "     verbose=0),\n",
      "          n_jobs=1), 0.65666666666666662: OneVsOneClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "     verbose=0),\n",
      "          n_jobs=1), 0.71500000000000008: MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 0.47333333333333327: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=0)}\n",
      "Vencedor: \n",
      "OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "     verbose=0),\n",
      "          n_jobs=1)\n",
      "Taxa de acerto do vencedor entre os dois algoritmos no mundo real: 88.88888888888889\n",
      "Taxa de acerto base: 44.444444\n",
      "Total de teste: 9\n"
     ]
    }
   ],
   "source": [
    "######################################## CAPITULO 10 ##########################\n",
    "\n",
    "#Classificando textos\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def vetorizar_texto(texto, tradutor):\n",
    "    vetor = [0] * len(tradutor)\n",
    "    for palavra in texto:\n",
    "        if palavra in tradutor:\n",
    "            posicao = tradutor[palavra]\n",
    "            vetor[posicao] += 1\n",
    "\n",
    "    return vetor\n",
    "\n",
    "\n",
    "classificacoes = pd.read_csv('D:\\\\Users\\\\313432\\\\Desktop\\\\Police Deaths\\\\machine-learning-master\\\\capitulo10\\\\emails.csv')\n",
    "textosPuros = classificacoes['email']\n",
    "textosQuebrados = textosPuros.str.lower().str.split(' ')\n",
    "dicionario = set()\n",
    "\n",
    "for lista in textosQuebrados:\n",
    "    dicionario.update(lista)\n",
    "\n",
    "totalDePalavras = len(dicionario)\n",
    "tuplas = zip(dicionario, range(totalDePalavras))\n",
    "tradutor = {palavra:indice for palavra, indice in tuplas}\n",
    "\n",
    "vetoresDeTexto = [vetorizar_texto(texto, tradutor) for texto in textosQuebrados]\n",
    "marcas = classificacoes['classificacao']\n",
    "\n",
    "X = vetoresDeTexto\n",
    "Y = marcas\n",
    "\n",
    "porcentagem_de_treino = 0.8\n",
    "\n",
    "tamanho_de_treino = int(porcentagem_de_treino * len(Y))\n",
    "tamanho_de_validacao = len(Y) - tamanho_de_treino\n",
    "\n",
    "treino_dados = X[0:tamanho_de_treino]\n",
    "treino_marcacoes = Y[0:tamanho_de_treino]\n",
    "\n",
    "validacao_dados = X[tamanho_de_treino:]\n",
    "validacao_marcacoes = Y[tamanho_de_treino:]\n",
    "\n",
    "def fit_and_predict(nome, modelo, treino_dados, treino_marcacoes):\n",
    "    k = 10\n",
    "    scores = cross_val_score(modelo, treino_dados, treino_marcacoes, cv = k)\n",
    "    taxa_de_acerto = np.mean(scores)\n",
    "    msg = \"Taxa de acerto do {0}: {1}\".format(nome, taxa_de_acerto)\n",
    "    print(msg)\n",
    "    return taxa_de_acerto\n",
    "\n",
    "def teste_real(modelo, validacao_dados, validacao_marcacoes):\n",
    "    resultado = modelo.predict(validacao_dados)\n",
    "\n",
    "    acertos = resultado == validacao_marcacoes\n",
    "\n",
    "    total_de_acertos = sum(acertos)\n",
    "    total_de_elementos = len(validacao_marcacoes)\n",
    "\n",
    "    taxa_de_acerto = 100.0 * total_de_acertos / total_de_elementos\n",
    "\n",
    "    msg = \"Taxa de acerto do vencedor entre os dois algoritmos no mundo real: {0}\".format(taxa_de_acerto)\n",
    "    print(msg)\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "modeloOneVsRest = OneVsRestClassifier(LinearSVC(random_state = 0))\n",
    "resultadoOneVsRest = fit_and_predict(\"OneVsRest\", modeloOneVsRest, treino_dados, treino_marcacoes)\n",
    "resultados[resultadoOneVsRest] = modeloOneVsRest\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "modeloOneVsOne = OneVsOneClassifier(LinearSVC(random_state = 0))\n",
    "resultadoOneVsOne = fit_and_predict(\"OneVsOne\", modeloOneVsOne, treino_dados, treino_marcacoes)\n",
    "resultados[resultadoOneVsOne] = modeloOneVsOne\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "modeloMultinomial = MultinomialNB()\n",
    "resultadoMultinomial = fit_and_predict(\"MultinomialNB\", modeloMultinomial, treino_dados, treino_marcacoes)\n",
    "resultados[resultadoMultinomial] = modeloMultinomial\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "modeloAdaBoost = AdaBoostClassifier(random_state=0)\n",
    "resultadoAdaBoost = fit_and_predict(\"AdaBoostClassifier\", modeloAdaBoost, treino_dados, treino_marcacoes)\n",
    "resultados[resultadoAdaBoost] = modeloAdaBoost\n",
    "\n",
    "print(resultados)\n",
    "\n",
    "maximo = max(resultados)\n",
    "vencedor = resultados[maximo]\n",
    "\n",
    "print(\"Vencedor: \")\n",
    "print(vencedor)\n",
    "\n",
    "vencedor.fit(treino_dados, treino_marcacoes)\n",
    "\n",
    "teste_real(vencedor, validacao_dados, validacao_marcacoes)\n",
    "\n",
    "acerto_base = max(Counter(validacao_marcacoes).values())\n",
    "taxa_de_acerto_base = 100.0 * acerto_base / len(validacao_marcacoes)\n",
    "print(\"Taxa de acerto base: %f\" % taxa_de_acerto_base)\n",
    "\n",
    "total_de_elementos = len(validacao_dados)\n",
    "print(\"Total de teste: %d\" % total_de_elementos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'a',\n",
       " 'o',\n",
       " 'que',\n",
       " 'e',\n",
       " 'do',\n",
       " 'da',\n",
       " 'em',\n",
       " 'um',\n",
       " 'para',\n",
       " 'com',\n",
       " 'não',\n",
       " 'uma',\n",
       " 'os',\n",
       " 'no',\n",
       " 'se',\n",
       " 'na',\n",
       " 'por',\n",
       " 'mais',\n",
       " 'as',\n",
       " 'dos',\n",
       " 'como',\n",
       " 'mas',\n",
       " 'ao',\n",
       " 'ele',\n",
       " 'das',\n",
       " 'à',\n",
       " 'seu',\n",
       " 'sua',\n",
       " 'ou',\n",
       " 'quando',\n",
       " 'muito',\n",
       " 'nos',\n",
       " 'já',\n",
       " 'eu',\n",
       " 'também',\n",
       " 'só',\n",
       " 'pelo',\n",
       " 'pela',\n",
       " 'até',\n",
       " 'isso',\n",
       " 'ela',\n",
       " 'entre',\n",
       " 'depois',\n",
       " 'sem',\n",
       " 'mesmo',\n",
       " 'aos',\n",
       " 'seus',\n",
       " 'quem',\n",
       " 'nas',\n",
       " 'me',\n",
       " 'esse',\n",
       " 'eles',\n",
       " 'você',\n",
       " 'essa',\n",
       " 'num',\n",
       " 'nem',\n",
       " 'suas',\n",
       " 'meu',\n",
       " 'às',\n",
       " 'minha',\n",
       " 'numa',\n",
       " 'pelos',\n",
       " 'elas',\n",
       " 'qual',\n",
       " 'nós',\n",
       " 'lhe',\n",
       " 'deles',\n",
       " 'essas',\n",
       " 'esses',\n",
       " 'pelas',\n",
       " 'este',\n",
       " 'dele',\n",
       " 'tu',\n",
       " 'te',\n",
       " 'vocês',\n",
       " 'vos',\n",
       " 'lhes',\n",
       " 'meus',\n",
       " 'minhas',\n",
       " 'teu',\n",
       " 'tua',\n",
       " 'teus',\n",
       " 'tuas',\n",
       " 'nosso',\n",
       " 'nossa',\n",
       " 'nossos',\n",
       " 'nossas',\n",
       " 'dela',\n",
       " 'delas',\n",
       " 'esta',\n",
       " 'estes',\n",
       " 'estas',\n",
       " 'aquele',\n",
       " 'aquela',\n",
       " 'aqueles',\n",
       " 'aquelas',\n",
       " 'isto',\n",
       " 'aquilo',\n",
       " 'estou',\n",
       " 'está',\n",
       " 'estamos',\n",
       " 'estão',\n",
       " 'estive',\n",
       " 'esteve',\n",
       " 'estivemos',\n",
       " 'estiveram',\n",
       " 'estava',\n",
       " 'estávamos',\n",
       " 'estavam',\n",
       " 'estivera',\n",
       " 'estivéramos',\n",
       " 'esteja',\n",
       " 'estejamos',\n",
       " 'estejam',\n",
       " 'estivesse',\n",
       " 'estivéssemos',\n",
       " 'estivessem',\n",
       " 'estiver',\n",
       " 'estivermos',\n",
       " 'estiverem',\n",
       " 'hei',\n",
       " 'há',\n",
       " 'havemos',\n",
       " 'hão',\n",
       " 'houve',\n",
       " 'houvemos',\n",
       " 'houveram',\n",
       " 'houvera',\n",
       " 'houvéramos',\n",
       " 'haja',\n",
       " 'hajamos',\n",
       " 'hajam',\n",
       " 'houvesse',\n",
       " 'houvéssemos',\n",
       " 'houvessem',\n",
       " 'houver',\n",
       " 'houvermos',\n",
       " 'houverem',\n",
       " 'houverei',\n",
       " 'houverá',\n",
       " 'houveremos',\n",
       " 'houverão',\n",
       " 'houveria',\n",
       " 'houveríamos',\n",
       " 'houveriam',\n",
       " 'sou',\n",
       " 'somos',\n",
       " 'são',\n",
       " 'era',\n",
       " 'éramos',\n",
       " 'eram',\n",
       " 'fui',\n",
       " 'foi',\n",
       " 'fomos',\n",
       " 'foram',\n",
       " 'fora',\n",
       " 'fôramos',\n",
       " 'seja',\n",
       " 'sejamos',\n",
       " 'sejam',\n",
       " 'fosse',\n",
       " 'fôssemos',\n",
       " 'fossem',\n",
       " 'for',\n",
       " 'formos',\n",
       " 'forem',\n",
       " 'serei',\n",
       " 'será',\n",
       " 'seremos',\n",
       " 'serão',\n",
       " 'seria',\n",
       " 'seríamos',\n",
       " 'seriam',\n",
       " 'tenho',\n",
       " 'tem',\n",
       " 'temos',\n",
       " 'tém',\n",
       " 'tinha',\n",
       " 'tínhamos',\n",
       " 'tinham',\n",
       " 'tive',\n",
       " 'teve',\n",
       " 'tivemos',\n",
       " 'tiveram',\n",
       " 'tivera',\n",
       " 'tivéramos',\n",
       " 'tenha',\n",
       " 'tenhamos',\n",
       " 'tenham',\n",
       " 'tivesse',\n",
       " 'tivéssemos',\n",
       " 'tivessem',\n",
       " 'tiver',\n",
       " 'tivermos',\n",
       " 'tiverem',\n",
       " 'terei',\n",
       " 'terá',\n",
       " 'teremos',\n",
       " 'terão',\n",
       " 'teria',\n",
       " 'teríamos',\n",
       " 'teriam']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.corpus.stopwords.words(\"portuguese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to C:\\nltk_data...\n",
      "[nltk_data]   Unzipping stemmers\\rslp.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "{'cont', 'antig', 'vez', 'descont', 'almej', 'segund', 'us', 'encontr', 'proxim', 'avis', 'alur', 'antecip', 'control', 'trabalh', 'ótim', 'naveg', 'opt', 'pert', 'ganh', 'minut', 'porém', 'maiúscul', 'capaz', 'plataform', 'expir', 'virtu', 'muit', 'bom', 'quant', 'inter', 'noit', 'escolh', 'pai', 'lingu', 'ver', 'fórmul', 'duvid', 'possu', 'filh', 'cuid', 'imprim', 'por', 'quer', 'premium', 'inform', 'aqu', 'desejo-t', 'pro', 'víde', 'pesquis', 'sei', 'correç', 'trilh', 'mac', 'entend', 'recomend', 'sab', 'python', 'seman', 'dificuldad', 'áre', 'convid', 'termin', 'pass', 'indic', 'di', 'ser', 'aplic', 'conheç', 'dia', 'respost', 'val', 'ambi', 'sistem', 'conhec', 'post', 'distanc', 'gráf', 'prát', 'envi', 'equip', 'vai', 'certific', 'faç', 'aind', 'ach', 'cust', 'djang', 'cadastr', 'inic', 'ob', 'faculdad', 'lid', 'confer', 'qualqu', 'tent', 'cobol', 'torn', 'pra', 'parec', 'favor', 'mai', 'err', 'troc', 'começ', 'excel', 'ond', 'conteúd', 'interess', 'colun', 'laravel', 'vers', 'gost', 'trav', 'real', 'mud', 'fic', 'javascrip', 'pod', 'fórum', 'carr', 'use', 'desenvolv', 'ano', 'jav', 'plan', 'email', 'aprend', 'googl', 'dep', 'iníci', 'aul', 'renov', 'boa', 'marketing', 'complet', 'seguint', 'mim', 'agradeç', 'pag', 'nenhum', 'necess', 'interfac', 'comput', 'absorv', 'nov', 'cs', 'emit', 'melhor', 'sent', 'design', 'caminh', 'desd', 'dess', 'payp', 'lógic', 'sit', 'sobr', 'identifiq', 'bancár', 'própri', 'brasil', 'tod', 'cresc', 'depend', 'faz', 'moder', 'antecipad', 'acess', 'cinc', 'depo', 'web', 'bas', 'desej', 'cri', 'plu', 'cart', 'vist', 'empr', 'digit', 'alguém', 'poi', 'io', 'moip', 'qual', 'ferrament', 'term', 'play', 'vou', 'hav', 'ont', 'html', 'framework', 'window', 'exercíci', 'realiz', 'coloq', 'comunidad', 'explic', 'além', 'exist', 'outr', 'program', 'olá', 'pal', 'compr', 'letr', 'dev', 'pret', 'parabém', 'independ', 'efetu', 'estud', 'via', 'pouc', 'ajud', 'vontad', 'poss', 'algum', 'transferenc', 'form', 'cancel', 'curs', 'premiun', 'qu', 'dúv', 'sum', 'pyqt', 'nom', 'part'}\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Taxa de acerto do OneVsRest: 0.8016666666666665\n",
      "Taxa de acerto do OneVsOne: 0.8016666666666665\n",
      "Taxa de acerto do MultinomialNB: 0.8300000000000001\n",
      "Taxa de acerto do AdaBoostClassifier: 0.5933333333333333\n",
      "{0.80166666666666653: OneVsOneClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "     verbose=0),\n",
      "          n_jobs=1), 0.83000000000000007: MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 0.59333333333333327: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=0)}\n",
      "Vencedor: \n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "Taxa de acerto do vencedor entre os dois algoritmos no mundo real: 77.77777777777777\n",
      "Taxa de acerto base: 44.444444\n",
      "Total de teste: 9\n"
     ]
    }
   ],
   "source": [
    "######################################## CAPITULO 11 ##########################\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import nltk\n",
    "\n",
    "classificacoes = pd.read_csv('D:\\\\Users\\\\313432\\\\Desktop\\\\Police Deaths\\\\machine-learning-master\\\\capitulo11\\\\emails.csv')\n",
    "textosPuros = classificacoes['email']\n",
    "frases = textosPuros.str.lower()\n",
    "textosQuebrados = [nltk.tokenize.word_tokenize(frase) for frase in frases]\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "\n",
    "dicionario = set()\n",
    "\n",
    "for lista in textosQuebrados:\n",
    "\tvalidas = [stemmer.stem(palavra) for palavra in lista if palavra not in stopwords and len(palavra) > 2]\n",
    "\tdicionario.update(validas)\n",
    "\n",
    "totalDePalavras = len(dicionario)\n",
    "print(totalDePalavras)\n",
    "print(dicionario)\n",
    "tuplas = zip(dicionario, range(totalDePalavras))\n",
    "tradutor = {palavra:indice for palavra, indice in tuplas}\n",
    "\n",
    "def vetorizar_texto(texto, tradutor, stemmer):\n",
    "    vetor = [0] * len(tradutor)\n",
    "    for palavra in texto:\n",
    "        if len(palavra) > 0:\n",
    "            raiz = stemmer.stem(palavra)\n",
    "            if raiz in tradutor:\n",
    "                posicao = tradutor[raiz]\n",
    "                vetor[posicao] += 1\n",
    "\n",
    "    return vetor\n",
    "\n",
    "vetoresDeTexto = [vetorizar_texto(texto, tradutor, stemmer) for texto in textosQuebrados]\n",
    "marcas = classificacoes['classificacao']\n",
    "\n",
    "print(vetoresDeTexto[0])\n",
    "\n",
    "X = vetoresDeTexto\n",
    "Y = marcas\n",
    "\n",
    "porcentagem_de_treino = 0.8\n",
    "\n",
    "tamanho_de_treino = int(porcentagem_de_treino * len(Y))\n",
    "tamanho_de_validacao = len(Y) - tamanho_de_treino\n",
    "\n",
    "treino_dados = X[0:tamanho_de_treino]\n",
    "treino_marcacoes = Y[0:tamanho_de_treino]\n",
    "\n",
    "validacao_dados = X[tamanho_de_treino:]\n",
    "validacao_marcacoes = Y[tamanho_de_treino:]\n",
    "\n",
    "def fit_and_predict(nome, modelo, treino_dados, treino_marcacoes):\n",
    "    k = 10\n",
    "    scores = cross_val_score(modelo, treino_dados, treino_marcacoes, cv = k)\n",
    "    taxa_de_acerto = np.mean(scores)\n",
    "    msg = \"Taxa de acerto do {0}: {1}\".format(nome, taxa_de_acerto)\n",
    "    print(msg)\n",
    "    return taxa_de_acerto\n",
    "\n",
    "def teste_real(modelo, validacao_dados, validacao_marcacoes):\n",
    "    resultado = modelo.predict(validacao_dados)\n",
    "\n",
    "    acertos = resultado == validacao_marcacoes\n",
    "\n",
    "    total_de_acertos = sum(acertos)\n",
    "    total_de_elementos = len(validacao_marcacoes)\n",
    "\n",
    "    taxa_de_acerto = 100.0 * total_de_acertos / total_de_elementos\n",
    "\n",
    "    msg = \"Taxa de acerto do vencedor entre os dois algoritmos no mundo real: {0}\".format(taxa_de_acerto)\n",
    "    print(msg)\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "modeloOneVsRest = OneVsRestClassifier(LinearSVC(random_state = 0))\n",
    "resultadoOneVsRest = fit_and_predict(\"OneVsRest\", modeloOneVsRest, treino_dados, treino_marcacoes)\n",
    "resultados[resultadoOneVsRest] = modeloOneVsRest\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "modeloOneVsOne = OneVsOneClassifier(LinearSVC(random_state = 0))\n",
    "resultadoOneVsOne = fit_and_predict(\"OneVsOne\", modeloOneVsOne, treino_dados, treino_marcacoes)\n",
    "resultados[resultadoOneVsOne] = modeloOneVsOne\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "modeloMultinomial = MultinomialNB()\n",
    "resultadoMultinomial = fit_and_predict(\"MultinomialNB\", modeloMultinomial, treino_dados, treino_marcacoes)\n",
    "resultados[resultadoMultinomial] = modeloMultinomial\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "modeloAdaBoost = AdaBoostClassifier(random_state=0)\n",
    "resultadoAdaBoost = fit_and_predict(\"AdaBoostClassifier\", modeloAdaBoost, treino_dados, treino_marcacoes)\n",
    "resultados[resultadoAdaBoost] = modeloAdaBoost\n",
    "\n",
    "print(resultados)\n",
    "\n",
    "maximo = max(resultados)\n",
    "vencedor = resultados[maximo]\n",
    "\n",
    "print(\"Vencedor: \")\n",
    "print(vencedor)\n",
    "\n",
    "vencedor.fit(treino_dados, treino_marcacoes)\n",
    "\n",
    "teste_real(vencedor, validacao_dados, validacao_marcacoes)\n",
    "\n",
    "acerto_base = max(Counter(validacao_marcacoes).values())\n",
    "taxa_de_acerto_base = 100.0 * acerto_base / len(validacao_marcacoes)\n",
    "print(\"Taxa de acerto base: %f\" % taxa_de_acerto_base)\n",
    "\n",
    "total_de_elementos = len(validacao_dados)\n",
    "print(\"Total de teste: %d\" % total_de_elementos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
